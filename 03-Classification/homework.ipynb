{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb65034",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1602962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d1780",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277ea77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a333d85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6613a5",
   "metadata": {},
   "source": [
    "### Checking for any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837d8fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d83cb2",
   "metadata": {},
   "source": [
    "### Missing values handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9385a511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['lead_source', 'industry', 'employment_status', 'location']\n",
      "Numerical columns: ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n"
     ]
    }
   ],
   "source": [
    "# For categorical -> 'NA'; numerical -> 0.0\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# exclude target if numeric\n",
    "if 'converted' in num_cols:\n",
    "    num_cols.remove('converted')\n",
    "\n",
    "print(\"Categorical columns:\", cat_cols)\n",
    "print(\"Numerical columns:\", num_cols)\n",
    "\n",
    "# Filling missing values\n",
    "df[cat_cols] = df[cat_cols].fillna('NA')\n",
    "df[num_cols] = df[num_cols].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd93bbb",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "most frequent observation (mode) for the column industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99753a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q1 - industry mode(s): ['retail']\n",
      "Q1 answer (mode): retail\n"
     ]
    }
   ],
   "source": [
    "# Q1: mode of 'industry'\n",
    "industry_mode = df['industry'].mode(dropna=False)\n",
    "print(\"\\nQ1 - industry mode(s):\", industry_mode.tolist())\n",
    "\n",
    "# topmost mode value\n",
    "industry_mode_value = industry_mode.iloc[0]\n",
    "print(\"Q1 answer (mode):\", industry_mode_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55efe55",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "correlation matrix for the numerical features(pairwise correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ebe2760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q2 - Correlations for the candidate pairs:\n",
      "interaction_count              & lead_score                     : 0.0099\n",
      "number_of_courses_viewed       & lead_score                     : -0.0049\n",
      "number_of_courses_viewed       & interaction_count              : -0.0236\n",
      "annual_income                  & interaction_count              : 0.0270\n",
      "\n",
      "Q2 answer → Strongest correlation is between annual_income and interaction_count (0.0270)\n"
     ]
    }
   ],
   "source": [
    "#Correlation between numeric features\n",
    "num_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "#correlation matrix\n",
    "corr = num_df.corr()\n",
    "\n",
    "# correlations for the four candidate pairs\n",
    "pairs = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count')\n",
    "]\n",
    "\n",
    "print(\"\\nQ2 - Correlations for the candidate pairs:\")\n",
    "for a, b in pairs:\n",
    "    if a in corr.columns and b in corr.columns:\n",
    "        print(f\"{a:30s} & {b:30s} : {corr.loc[a,b]:.4f}\")\n",
    "    else:\n",
    "        print(f\"{a} or {b} not found among numeric columns\")\n",
    "\n",
    "# The pair with the largest absolute correlation\n",
    "best_pair = max(pairs, key=lambda x: abs(corr.loc[x[0], x[1]]))\n",
    "best_value = corr.loc[best_pair[0], best_pair[1]]\n",
    "\n",
    "print(f\"\\nQ2 answer → Strongest correlation is between {best_pair[0]} and {best_pair[1]} \"\n",
    "      f\"({best_value:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2f447d",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48886818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data split sizes (rows):\n",
      "Train: 877\n",
      "Val:   292\n",
      "Test:  293\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data (60/20/20)\n",
    "# First we split train_temp (60%) and test_temp (40%); then split test_temp into val/test (each 20% of total)\n",
    "X = df.drop(columns=['converted']).copy()\n",
    "y = df['converted'].copy()\n",
    "\n",
    "# First split: train 60%, temp 40%\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "# Second split: split temp into val/test equally (each 20% of total)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"\\nData split sizes (rows):\")\n",
    "print(\"Train:\", X_train.shape[0])\n",
    "print(\"Val:  \", X_val.shape[0])\n",
    "print(\"Test: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a3c08",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa160a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical columns used for MI: ['lead_source', 'industry', 'employment_status', 'location']\n",
      "\n",
      "Q3 - Mutual information scores (training set only):\n",
      "lead_source          0.03\n",
      "industry             0.01\n",
      "employment_status    0.01\n",
      "location             0.00\n",
      "dtype: float64\n",
      "\n",
      "Q3 - candidate scores:\n",
      "industry 0.01\n",
      "location 0.0\n",
      "lead_source 0.03\n",
      "employment_status 0.01\n"
     ]
    }
   ],
   "source": [
    "#  mutual information between 'converted' and categorical variables, using training set only.\n",
    "# categorical variables for mutual information \n",
    "cat_cols_train = [c for c in X_train.columns if X_train[c].dtype == 'object' or str(X_train[c].dtype).startswith('category')]\n",
    "print(\"\\nCategorical columns used for MI:\", cat_cols_train)\n",
    "\n",
    "# Encode categories as integers for mutual_info_classif\n",
    "# We'll further use pandas factorize per column to convert categories to ints\n",
    "X_train_cat_encoded = pd.DataFrame()\n",
    "for c in cat_cols_train:\n",
    "    X_train_cat_encoded[c] = pd.factorize(X_train[c])[0]\n",
    "\n",
    "# mutual information\n",
    "mi = mutual_info_classif(X_train_cat_encoded.values, y_train.values, discrete_features=True, random_state=42)\n",
    "mi_series = pd.Series(mi, index=cat_cols_train).sort_values(ascending=False)\n",
    "mi_rounded = mi_series.round(2)\n",
    "print(\"\\nQ3 - Mutual information scores (training set only):\")\n",
    "print(mi_rounded)\n",
    "\n",
    "# variables with the biggest MI\n",
    "candidates_q3 = ['industry','location','lead_source','employment_status']\n",
    "print(\"\\nQ3 - candidate scores:\")\n",
    "for c in candidates_q3:\n",
    "    val = mi_rounded.get(c, None)\n",
    "    print(c, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a0a96d",
   "metadata": {},
   "source": [
    "### Question 4: \n",
    "Train logistic regression with one-hot encoding for categoricals, on training set; evaluate on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fcb3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q4 - Validation accuracy (rounded to 2 decimals): 0.68\n",
      "Q4 - Validation accuracy (full): 0.6815068493150684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# categorical and numerical columns\n",
    "all_cat_cols = [c for c in X_train.columns \n",
    "                if X_train[c].dtype == 'object' or str(X_train[c].dtype).startswith('category')]\n",
    "all_num_cols = [c for c in X_train.columns if c not in all_cat_cols]\n",
    "\n",
    "# Preprocessing: OneHotEncoder for categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), all_cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Logistic Regression model\n",
    "model = LogisticRegression(\n",
    "    solver='liblinear', \n",
    "    C=1.0, \n",
    "    max_iter=1000, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combining preprocessing and model into a pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "# Evaluate accuracy\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "acc_val_rounded = round(acc_val, 2)\n",
    "\n",
    "print(\"\\nQ4 - Validation accuracy (rounded to 2 decimals):\", acc_val_rounded)\n",
    "print(\"Q4 - Validation accuracy (full):\", acc_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda3762",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5646a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline validation accuracy: 0.681507\n",
      "Removing 'industry': val_acc=0.688356, diff=-0.006849\n",
      "Removing 'employment_status': val_acc=0.681507, diff=0.000000\n",
      "Removing 'lead_score': val_acc=0.674658, diff=0.006849\n",
      "\n",
      "Q5 - Differences (baseline - without_feature):\n",
      "{'industry': -0.006849315068493178, 'employment_status': 0.0, 'lead_score': 0.006849315068493067}\n",
      "\n",
      "Q5 answer → Least useful feature: 'industry' (smallest difference)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# baseline validation accuracy from Q4\n",
    "baseline_acc = acc_val\n",
    "print(f\"\\nBaseline validation accuracy: {baseline_acc:.6f}\")\n",
    "\n",
    "# candidate features to test\n",
    "candidates_q5 = ['industry', 'employment_status', 'lead_score']\n",
    "\n",
    "# Function to train & evaluate without a specific feature\n",
    "def train_and_eval_without_feature(X_tr, y_tr, X_v, y_v, drop_feature):\n",
    "    features_subset = [f for f in X_tr.columns if f != drop_feature]\n",
    "    cat_cols_sub = [c for c in features_subset if X_tr[c].dtype == 'object' or str(X_tr[c].dtype).startswith('category')]\n",
    "    \n",
    "    pre = ColumnTransformer(transformers=[\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols_sub)\n",
    "    ], remainder='passthrough')\n",
    "    \n",
    "    clf = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    p = Pipeline([('pre', pre), ('clf', clf)])\n",
    "    p.fit(X_tr[features_subset], y_tr)\n",
    "    \n",
    "    yv_pred = p.predict(X_v[features_subset])\n",
    "    return accuracy_score(y_v, yv_pred)\n",
    "\n",
    "differences = {}\n",
    "for feat in candidates_q5:\n",
    "    acc_without = train_and_eval_without_feature(X_train, y_train, X_val, y_val, feat)\n",
    "    diff = baseline_acc - acc_without\n",
    "    differences[feat] = diff\n",
    "    print(f\"Removing '{feat}': val_acc={acc_without:.6f}, diff={diff:.6f}\")\n",
    "\n",
    "print(\"\\nQ5 - Differences (baseline - without_feature):\")\n",
    "print(differences)\n",
    "\n",
    "# The least useful feature (smallest difference)\n",
    "least_useful = min(differences, key=differences.get)\n",
    "print(f\"\\nQ5 answer → Least useful feature: '{least_useful}' (smallest difference)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60618514",
   "metadata": {},
   "source": [
    "### Question 6: \n",
    "Different regularization strengths (C values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1177eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01: validation accuracy = 0.688356 (rounded to 3 decimals → 0.688)\n",
      "C=0.1: validation accuracy = 0.681507 (rounded to 3 decimals → 0.682)\n",
      "C=1: validation accuracy = 0.681507 (rounded to 3 decimals → 0.682)\n",
      "C=10: validation accuracy = 0.681507 (rounded to 3 decimals → 0.682)\n",
      "C=100: validation accuracy = 0.681507 (rounded to 3 decimals → 0.682)\n",
      "\n",
      "Q6 - Validation accuracies by C value:\n",
      "{0.01: 0.6883561643835616, 0.1: 0.6815068493150684, 1: 0.6815068493150684, 10: 0.6815068493150684, 100: 0.6815068493150684}\n",
      "\n",
      "Q6 answer → Best C: 0.01 (validation accuracy = 0.688356)\n"
     ]
    }
   ],
   "source": [
    "# Q6: different regularization strengths (C values)\n",
    "Cs = [0.01, 0.1, 1, 10, 100]\n",
    "val_accs = {}\n",
    "\n",
    "for C in Cs:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    pipe = Pipeline([\n",
    "        ('pre', preprocessor),  \n",
    "        ('clf', model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    yv_pred = pipe.predict(X_val)\n",
    "    acc = accuracy_score(y_val, yv_pred)\n",
    "    val_accs[C] = acc\n",
    "    print(f\"C={C}: validation accuracy = {acc:.6f} (rounded to 3 decimals → {round(acc,3)})\")\n",
    "\n",
    "# best C (highest accuracy; if tie → smallest C)\n",
    "best_acc = max(val_accs.values())\n",
    "best_Cs = [C for C, acc in val_accs.items() if acc == best_acc]\n",
    "chosen_C = min(best_Cs)\n",
    "\n",
    "print(\"\\nQ6 - Validation accuracies by C value:\")\n",
    "print(val_accs)\n",
    "print(f\"\\nQ6 answer → Best C: {chosen_C} (validation accuracy = {best_acc:.6f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
