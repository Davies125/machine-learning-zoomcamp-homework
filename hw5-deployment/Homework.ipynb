{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ce9392",
   "metadata": {},
   "source": [
    "# Homework 5 - Model Deployment\n",
    "# This notebook covers model deployment using FastAPI and Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb83d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: Load pipeline and score a record\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44f07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, filename):\n",
    "    \"\"\"Download file if it doesn't exist\"\"\"\n",
    "    import os\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        response = requests.get(url)\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Download completed!\")\n",
    "    else:\n",
    "        print(f\"{filename} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32aa2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_v1.bin already exists\n"
     ]
    }
   ],
   "source": [
    "# Download the model\n",
    "model_url = \"https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\"\n",
    "download_file(model_url, \"pipeline_v1.bin\")\n",
    "\n",
    "# Load the model\n",
    "def load_model(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        pipeline = pickle.load(f)\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42570b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator DictVectorizer from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/base.py:440: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.6.1 when using version 1.7.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the pipeline\n",
    "pipeline = load_model(\"pipeline_v1.bin\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Prepare the client data\n",
    "client = {\n",
    "    \"lead_source\": \"paid_ads\",\n",
    "    \"number_of_courses_viewed\": 2,\n",
    "    \"annual_income\": 79276.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91fe2f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 3: Probability of conversion: 0.534\n",
      "Closest option: 0.533\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "def predict_conversion(pipeline, client_data):\n",
    "    # Convert to list of one record for prediction\n",
    "    X = [client_data]\n",
    "    # Get probability of positive class (conversion)\n",
    "    proba = pipeline.predict_proba(X)[0, 1]\n",
    "    return proba\n",
    "\n",
    "# Get probability\n",
    "probability = predict_conversion(pipeline, client)\n",
    "print(f\"Question 3: Probability of conversion: {probability:.3f}\")\n",
    "\n",
    "# Compare with options\n",
    "options = [0.333, 0.533, 0.733, 0.933]\n",
    "closest_option = min(options, key=lambda x: abs(x - probability))\n",
    "print(f\"Closest option: {closest_option}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45bdd8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastAPI code saved to main.py\n",
      "Question 4: Probability of conversion: 0.534\n",
      "Closest option: 0.534\n"
     ]
    }
   ],
   "source": [
    "# Question 4: Create FastAPI service\n",
    "# This code goes in a separate file: main.py\n",
    "\n",
    "fastapi_code = '''\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import pickle\n",
    "\n",
    "# Load the model\n",
    "with open('pipeline_v1.bin', 'rb') as f:\n",
    "    pipeline = pickle.load(f)\n",
    "\n",
    "# Define request model\n",
    "class ClientData(BaseModel):\n",
    "    lead_source: str\n",
    "    number_of_courses_viewed: int\n",
    "    annual_income: float\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(client: ClientData):\n",
    "    # Convert to dict\n",
    "    client_dict = client.dict()\n",
    "    \n",
    "    # Prepare for prediction (needs to be a list of one record)\n",
    "    X = [client_dict]\n",
    "    \n",
    "    # Get probability\n",
    "    proba = pipeline.predict_proba(X)[0, 1]\n",
    "    \n",
    "    return {\"conversion_probability\": round(proba, 3)}\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\"message\": \"Lead Scoring API\"}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "'''\n",
    "\n",
    "# Save the FastAPI code to a file\n",
    "with open('main.py', 'w') as f:\n",
    "    f.write(fastapi_code)\n",
    "\n",
    "print(\"FastAPI code saved to main.py\")\n",
    "\n",
    "# Now let's test the prediction for Question 4\n",
    "def test_question4_prediction():\n",
    "    \"\"\"Test the prediction for the client in Question 4\"\"\"\n",
    "    client_q4 = {\n",
    "        \"lead_source\": \"organic_search\",\n",
    "        \"number_of_courses_viewed\": 4,\n",
    "        \"annual_income\": 80304.0\n",
    "    }\n",
    "    \n",
    "    probability_q4 = predict_conversion(pipeline, client_q4)\n",
    "    print(f\"Question 4: Probability of conversion: {probability_q4:.3f}\")\n",
    "    \n",
    "    # Compare with options\n",
    "    options_q4 = [0.334, 0.534, 0.734, 0.934]\n",
    "    closest_option_q4 = min(options_q4, key=lambda x: abs(x - probability_q4))\n",
    "    print(f\"Closest option: {closest_option_q4}\")\n",
    "    \n",
    "    return probability_q4\n",
    "\n",
    "# Run the test\n",
    "prob_q4 = test_question4_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34e67690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile and requirements.txt created\n",
      "Test script created: test_api.py\n"
     ]
    }
   ],
   "source": [
    "# Question 6: Create Dockerfile and test the container\n",
    "\n",
    "# First, let's create a requirements file\n",
    "requirements_content = '''\n",
    "fastapi==0.104.1\n",
    "uvicorn==0.24.0\n",
    "scikit-learn==1.6.1\n",
    "pydantic==2.5.0\n",
    "'''\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements_content)\n",
    "\n",
    "# Create Dockerfile\n",
    "dockerfile_content = '''\n",
    "FROM agrigorev/zoomcamp-model:2025\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy requirements and install dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "# Copy the application code\n",
    "COPY main.py .\n",
    "COPY pipeline_v1.bin .\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 8000\n",
    "\n",
    "# Command to run the application\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "'''\n",
    "\n",
    "with open('Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile_content)\n",
    "\n",
    "print(\"Dockerfile and requirements.txt created\")\n",
    "\n",
    "\n",
    "# Let's also create a test script\n",
    "test_script = '''\n",
    "import requests\n",
    "\n",
    "def test_api():\n",
    "    url = \"http://localhost:8000/predict\"\n",
    "    client = {\n",
    "        \"lead_source\": \"organic_search\",\n",
    "        \"number_of_courses_viewed\": 4,\n",
    "        \"annual_income\": 80304.0\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=client)\n",
    "        result = response.json()\n",
    "        print(f\"API Response: {result}\")\n",
    "        return result['conversion_probability']\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_api()\n",
    "'''\n",
    "\n",
    "with open('test_api.py', 'w') as f:\n",
    "    f.write(test_script)\n",
    "\n",
    "print(\"Test script created: test_api.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
